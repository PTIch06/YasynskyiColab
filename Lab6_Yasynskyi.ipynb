{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnibo/WsMEoNgC7kisgQxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PTIch06/YasynskyiColab/blob/main/Lab6_Yasynskyi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Лабораторна робота №6\n",
        "##з дисципліни \"Нейронні мережі\"\n",
        "###студента групи КН-31/2\n",
        "###Ясинського Дениса\n",
        "###Варіант №11\n",
        "\n"
      ],
      "metadata": {
        "id": "j2ANgyyR9D7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Виконати вирішення задачі класифікації для 3 класів з набору даних food101 з використанням різних моделей нейронних мереж:<br>\n",
        "1) CNN модель з лабораторної роботи 4<br>\n",
        "2) Resnet модель<br>\n",
        "3) Efficientnet модель (моделі 1.1-1.3 з використанням оптимізатора Adam)<br>\n",
        "4) Моделі 1.2,1.3 з використанням оптимізатора SGD.<br>\n",
        "5) Моделі 1.2,1.3 отримані за допомогою tf.keras.applications та треновані з використанням fine-tuning (останні 10 шарів)<br>\n",
        "2. Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком групи.\n",
        "3. Порівняти результати моделювання із використанням TensorBoard\n",
        "4. Графік(и) порівняння результатів завантажити у форматі .svg та вставити у підсумковий файл поряд із та відповідними висновками"
      ],
      "metadata": {
        "id": "Yl9uxLT8gyHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Завантажимо файли\n",
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"101_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvYxd3qwhaTN",
        "outputId": "123b6706-5786-4ffa-ccbc-6133dd805ed9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-24 20:05:17--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.213.128, 173.194.214.128, 173.194.215.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.213.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip.1’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   168MB/s    in 9.3s    \n",
            "\n",
            "2022-05-24 20:05:27 (166 MB/s) - ‘101_food_classes_10_percent.zip.1’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Виділимо класи за варіантом (10, 40, 70)\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "data_dir_train = pathlib.Path(\"101_food_classes_10_percent/train/\") \n",
        "data_dir_test = pathlib.Path(\"101_food_classes_10_percent/test/\")\n",
        "num_food_images_train = len(os.listdir(data_dir_train))\n",
        "print('Count of images are in a file:', num_food_images_train)\n",
        "\n",
        "class_names = np.array(sorted([item.name for item in data_dir_train.glob('*')]))\n",
        "new_class_names = [class_names[10], class_names[40],class_names[70]]\n",
        "print('Our classes:', new_class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1QMnARykhtF",
        "outputId": "f170fb6c-7f23-49ce-a6c5-9cde4ac277aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of images are in a file: 101\n",
            "Our classes: ['bruschetta', 'french_fries', 'pad_thai']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Видалимо зайве\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "for name in class_names:\n",
        "  if name != new_class_names[0] and name != new_class_names[1] and name != new_class_names[2]:\n",
        "    dirpath = Path(data_dir_train) / name\n",
        "    dirpath_test = Path(data_dir_test) / name\n",
        "    if dirpath_test.exists() and dirpath_test.is_dir():\n",
        "        shutil.rmtree(dirpath)\n",
        "        shutil.rmtree(dirpath_test)\n",
        "print('Test:', os.listdir(data_dir_test))\n",
        "print('Train:', os.listdir(data_dir_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Y2HHZMshK-",
        "outputId": "43bb9777-9737-443d-8685-ad7eb4805af7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: ['french_fries', 'bruschetta', 'pad_thai']\n",
            "Train: ['french_fries', 'bruschetta', 'pad_thai']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Конвертуємо зображення на дані\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAt0VughmXRe",
        "outputId": "c5bfa418-1cc3-42b2-f26d-92887704b3f5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Урізноманітнимо зображення\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                  target_size=(224, 224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3x3L2zrs7cn",
        "outputId": "84be2690-67bd-49be-bfed-d61ca77d8159"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Навчання"
      ],
      "metadata": {
        "id": "4nHIRWQYmq-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "m_1 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "m_1.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "tb_callback_1 = tf.keras.callbacks.TensorBoard(log_dir='logs/cnn', histogram_freq=1)\n",
        "\n",
        "h_1 = m_1.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmPkyzRZmkzi",
        "outputId": "998ab6d9-9be5-44c1-979e-4ea32f843ac0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 54s 2s/step - loss: 1.2522 - accuracy: 0.3720 - val_loss: 1.0684 - val_accuracy: 0.3600\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 51s 2s/step - loss: 1.0448 - accuracy: 0.4400 - val_loss: 0.9964 - val_accuracy: 0.4844\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 53s 2s/step - loss: 0.9306 - accuracy: 0.5600 - val_loss: 0.8854 - val_accuracy: 0.5867\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 53s 2s/step - loss: 0.8891 - accuracy: 0.5907 - val_loss: 0.8699 - val_accuracy: 0.6222\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 52s 2s/step - loss: 0.8248 - accuracy: 0.6480 - val_loss: 0.8447 - val_accuracy: 0.6844\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 52s 2s/step - loss: 0.7908 - accuracy: 0.6547 - val_loss: 0.8079 - val_accuracy: 0.6889\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 57s 2s/step - loss: 0.7683 - accuracy: 0.6813 - val_loss: 0.8761 - val_accuracy: 0.6311\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 51s 2s/step - loss: 0.7729 - accuracy: 0.6547 - val_loss: 0.9490 - val_accuracy: 0.6133\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 52s 2s/step - loss: 0.8708 - accuracy: 0.6067 - val_loss: 0.8855 - val_accuracy: 0.5867\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 52s 2s/step - loss: 0.8656 - accuracy: 0.6000 - val_loss: 0.8320 - val_accuracy: 0.6756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet \n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "m_2 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "m_2.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_2 = tf.keras.callbacks.TensorBoard(log_dir='logs/resnet(adam)notunnig', histogram_freq=1)\n",
        "\n",
        "m_2.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "h_2 = m_2.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deSW7EmBn5RL",
        "outputId": "551b4611-667d-48a5-ad9a-085024743585"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 299s 12s/step - loss: 0.4095 - accuracy: 0.8467 - val_loss: 0.2662 - val_accuracy: 0.9200\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 267s 11s/step - loss: 0.1491 - accuracy: 0.9507 - val_loss: 0.2434 - val_accuracy: 0.9156\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 268s 11s/step - loss: 0.1277 - accuracy: 0.9573 - val_loss: 0.2179 - val_accuracy: 0.9156\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 295s 12s/step - loss: 0.1031 - accuracy: 0.9653 - val_loss: 0.2113 - val_accuracy: 0.9156\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 269s 11s/step - loss: 0.0786 - accuracy: 0.9760 - val_loss: 0.2066 - val_accuracy: 0.9333\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 293s 12s/step - loss: 0.0631 - accuracy: 0.9787 - val_loss: 0.2237 - val_accuracy: 0.9333\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 294s 12s/step - loss: 0.0596 - accuracy: 0.9760 - val_loss: 0.2076 - val_accuracy: 0.9289\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 292s 12s/step - loss: 0.0551 - accuracy: 0.9880 - val_loss: 0.2081 - val_accuracy: 0.9289\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 271s 11s/step - loss: 0.0547 - accuracy: 0.9880 - val_loss: 0.2098 - val_accuracy: 0.9289\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 292s 12s/step - loss: 0.0436 - accuracy: 0.9907 - val_loss: 0.2140 - val_accuracy: 0.9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Efficientnet(Adam)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "m_3 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "m_3.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_2 = tf.keras.callbacks.TensorBoard(log_dir='logs/resnet(adam)notunnig', histogram_freq=1)\n",
        "\n",
        "m_3.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "h_3 = m_3.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub4BauUNm43l",
        "outputId": "0b64edf8-e139-43f0-8a0a-d76f4a862607"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 301s 12s/step - loss: 0.8466 - accuracy: 0.6813 - val_loss: 0.3162 - val_accuracy: 0.8889\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 287s 12s/step - loss: 0.1867 - accuracy: 0.9427 - val_loss: 0.2620 - val_accuracy: 0.9022\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 261s 11s/step - loss: 0.1328 - accuracy: 0.9680 - val_loss: 0.2049 - val_accuracy: 0.9200\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 287s 12s/step - loss: 0.1141 - accuracy: 0.9667 - val_loss: 0.2168 - val_accuracy: 0.9111\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 289s 12s/step - loss: 0.1105 - accuracy: 0.9653 - val_loss: 0.1871 - val_accuracy: 0.9289\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 261s 11s/step - loss: 0.0862 - accuracy: 0.9747 - val_loss: 0.1905 - val_accuracy: 0.9289\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 261s 11s/step - loss: 0.0749 - accuracy: 0.9773 - val_loss: 0.2049 - val_accuracy: 0.9111\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 286s 12s/step - loss: 0.0789 - accuracy: 0.9827 - val_loss: 0.1881 - val_accuracy: 0.9289\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 261s 11s/step - loss: 0.0683 - accuracy: 0.9867 - val_loss: 0.1887 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 286s 12s/step - loss: 0.0521 - accuracy: 0.9880 - val_loss: 0.1900 - val_accuracy: 0.9156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Efficientnet SGD\n",
        "m_4 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
        "                   trainable=False),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "m_4.build([None, 224, 224, 3])\n",
        "\n",
        "tb_callback_4 = tf.keras.callbacks.TensorBoard(log_dir='logs/effnet(sgd)notunning', histogram_freq=1)\n",
        "\n",
        "m_4.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "h_4 = m_4.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks = [tb_callback_4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxmnRiWjnOBV",
        "outputId": "ed1033d2-4707-48c6-cab3-625106fd5305"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 0.6784 - accuracy: 0.7893 - val_loss: 0.4687 - val_accuracy: 0.9156\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 60s 3s/step - loss: 0.3622 - accuracy: 0.9467 - val_loss: 0.3335 - val_accuracy: 0.9244\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 69s 3s/step - loss: 0.2594 - accuracy: 0.9693 - val_loss: 0.2769 - val_accuracy: 0.9333\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 60s 3s/step - loss: 0.2081 - accuracy: 0.9653 - val_loss: 0.2430 - val_accuracy: 0.9378\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 60s 2s/step - loss: 0.1771 - accuracy: 0.9800 - val_loss: 0.2222 - val_accuracy: 0.9422\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 69s 3s/step - loss: 0.1623 - accuracy: 0.9773 - val_loss: 0.2070 - val_accuracy: 0.9467\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 68s 3s/step - loss: 0.1454 - accuracy: 0.9787 - val_loss: 0.1965 - val_accuracy: 0.9467\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 68s 3s/step - loss: 0.1444 - accuracy: 0.9693 - val_loss: 0.1891 - val_accuracy: 0.9467\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 68s 3s/step - loss: 0.1300 - accuracy: 0.9813 - val_loss: 0.1821 - val_accuracy: 0.9511\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 60s 3s/step - loss: 0.1200 - accuracy: 0.9760 - val_loss: 0.1764 - val_accuracy: 0.9511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet SGD fine-tuning\n",
        "import tensorflow as tf\n",
        "efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB0(classes=3, weights=None)\n",
        "for layer in efficientnet_model.layers:\n",
        "  layer.trainable = False;\n",
        "\n",
        "for layer in efficientnet_model.layers[-10:]:\n",
        "  layer.trainable = True;\n",
        "tb_callback_5 = tf.keras.callbacks.TensorBoard(log_dir='logs/effnet(sgd)tunnig', histogram_freq=1)\n",
        "\n",
        "efficientnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "h_5 = efficientnet_model.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tb_callback_5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imaC9hrHnUDF",
        "outputId": "97241bb1-cf5b-4cf3-d340-65a7b26a2102"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1026 - accuracy: 0.3187 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 1.1001 - accuracy: 0.3440 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 1.1015 - accuracy: 0.3333 - val_loss: 1.1009 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 75s 3s/step - loss: 1.1024 - accuracy: 0.3147 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 67s 3s/step - loss: 1.0997 - accuracy: 0.3427 - val_loss: 1.1005 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 67s 3s/step - loss: 1.1006 - accuracy: 0.3253 - val_loss: 1.1040 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 75s 3s/step - loss: 1.1021 - accuracy: 0.3093 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 1.1021 - accuracy: 0.3173 - val_loss: 1.1000 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 66s 3s/step - loss: 1.1009 - accuracy: 0.3240 - val_loss: 1.0991 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 1.0995 - accuracy: 0.3507 - val_loss: 1.1007 - val_accuracy: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Efficientnet SGD fine-tuning\n",
        "eff_model = tf.keras.applications.efficientnet.EfficientNetB0(classes=3, weights=None)\n",
        "for layer in eff_model.layers:\n",
        "  layer.trainable = False;\n",
        "\n",
        "for layer in eff_model.layers[-10:]:\n",
        "  layer.trainable = True;\n",
        "\n",
        "tensorboard_6 = tf.keras.callbacks.TensorBoard(log_dir='logs/efficientnet(sgd)tunnig', histogram_freq=1,\n",
        "                                               write_graph=True, write_images=False)\n",
        "\n",
        "eff_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history_model_6 = eff_model.fit(train_data_augmented,\n",
        "                          epochs=10,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data),\n",
        "                          callbacks=[tensorboard_6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEFrjXTioY1R",
        "outputId": "992d93af-a834-49eb-cecb-14f6d56bed55"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 82s 3s/step - loss: 1.1007 - accuracy: 0.3173 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 65s 3s/step - loss: 1.1019 - accuracy: 0.3213 - val_loss: 1.0994 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 64s 3s/step - loss: 1.1013 - accuracy: 0.3307 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 74s 3s/step - loss: 1.1023 - accuracy: 0.3227 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1030 - accuracy: 0.2920 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1012 - accuracy: 0.3147 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1017 - accuracy: 0.3107 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1011 - accuracy: 0.2947 - val_loss: 1.0994 - val_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 65s 3s/step - loss: 1.1022 - accuracy: 0.3173 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 73s 3s/step - loss: 1.1045 - accuracy: 0.2840 - val_loss: 1.0996 - val_accuracy: 0.3333\n"
          ]
        }
      ]
    }
  ]
}